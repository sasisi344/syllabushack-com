# 記事作成用データセット要件（Career & Trend）

「キャリア」と「トレンド」の記事を残り各5〜6本作成し、説得力を持たせるために収集すべきデータセットリストです。
これらをPerplexityやGoogle検索、公式サイトから収集し、NotebookLMやGeminiのソースとすることで、質の高い記事が量産できます。

## 1. Career（キャリア戦略）用データセット

「資格は役に立つのか？」「年収は上がるのか？」という読者の疑問に、**数字と市場価値**で答えるためのデータです。

### A. 年収・待遇データ（Money）
*   **資格別平均年収ランキング**:
    *   ソース: doda「平均年収ランキング一覧（職種・資格別）」、Tech総研
    *   *狙い*: FE（基本情報）やAP（応用情報）取得者の年収中央値を提示。
*   **資格手当の相場**:
    *   ソース: 人事院「民間給与の実態」、各社求人票の募集要項
    *   *狙い*: 「月5,000円〜20,000円」などの具体的数値を出し、生涯獲得賃金の差を試算する。

### B. 求人市場データ（Market）
*   **「必須要件」vs「歓迎要件」ヒット数**:
    *   ソース: Indeed, Green, Wantedly
    *   *収集方法*: キーワード「基本情報技術者」で検索し、必須（Must）と歓迎（Want）の件数比率を調査。
    *   *狙い*: 「未経験なら必須級だが、経験者なら誤差」という現実を可視化する。
*   **フリーランス・副業単価**:
    *   ソース: レバテックフリーランスなどの単価相場表、クラウドワークス
    *   *狙い*: 「資格単体では案件獲得不可だが、ポートフォリオ＋資格で単価＋5万」のような相関データ。

### C. キャリアパス事例（Story）
*   **未経験からのステップアップ事例**:
    *   パターン: 運用監視（ITパス/FE） → 設計構築（AP/高度） → PM/コンサル
    *   *狙い*: 資格が「パスポート（通行手形）」として機能するフェーズを定義する。

---

## 2. Trend（トレンド・情報）用データセット

「今、何が起きているか」「これからどうなるか」を、**IPAの一次情報と社会動向**から読み解くためのデータです。

### A. IPA公式統計（Official Stats）
*   **応募者数・合格率の推移**:
    *   ソース: IPA「情報処理技術者試験・情報処理安全確保支援士試験 推移表」
    *   *狙い*: 非IT系（ITパスポート）の爆発的増加と、エンジニア向け試験（FE/AP）の横ばい・変化をグラフ化。
    *   *記事ネタ*: 「なぜ今、文系社員がこぞってITパスポートを受けるのか？」
*   **受験者の属性データ**:
    *   ソース: IPA統計資料（勤務先、経験年数、年齢層）
    *   *狙い*: 「社会人のリスキリング需要」をデータで証明する。

### B. シラバス変更点（Syllabus Diff）
*   **追加された用語リスト（重要）**:
    *   ソース: IPAシラバス変更履歴（Ver.6.x -> Ver.xなど）
    *   *収集対象*: 「生成AI」「プロンプトエンジニアリング」「ゼロトラスト」など、新規追加用語。
    *   *記事ネタ*: 「シラバス変更から読み解く、国が求めている人材像」。

### C. 社会・企業動向（Social Impact）
*   **企業・官公庁の導入事例**:
    *   ソース: Nikkei XTECH、各社プレスリリース（「全社員取得」「昇格要件化」など）
    *   *企業例*: ニトリ、サイバーエージェント、官公庁の入札要件など。
    *   *狙い*: 「資格はオワコンではない（企業論理としては強化されている）」ことを示す。

---

## 3. 効率的な収集・活用ワークフロー

### Step 1: Perplexity / Gneiss (Gemini) で収集
以下のプロンプトで「表形式」のデータを収集させます。

> 「基本情報技術者試験の過去5年間の応募者数推移と合格率を、表形式で作成してください。出典元URLも明記して。」
> 「ITパスポートの取得を推奨または義務化している日本企業の最新事例を5社リストアップし、その目的と効果を要約して。」

### Step 2: NotebookLMにソースとして投入
収集した統計データ（PDFやWeb記事のコピペ）をNotebookLMに放り込みます。

### Step 3: 記事の骨子生成
> 「アップロードした統計データを元に、『ITパスポートは意味がないというのは嘘であるデータ的根拠』というテーマで記事構成案を作って」

このフローにより、主観（ポジショントーク）だけでなく、**データ（客観的事実）に基づいた説得力のある記事**を量産できます。
